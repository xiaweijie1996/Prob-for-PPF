Host: gcn67.local.snellius.surf.nl
Thu Sep 11 15:26:44 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:E3:00.0 Off |                    0 |
| N/A   31C    P0             51W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
torch 2.8.0+cu128 cuda? True
/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/tensorpowerflow/utils.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/gpfs/home4/wxia/Prob-for-PPF
/gpfs/home4/wxia/Prob-for-PPF
Default case loaded.

Chunk:   0%|          | 0/1 [00:00<?, ?it/s]
Chunk: 1 of 1:   0%|          | 0/1 [00:00<?, ?it/s]
                                                    
/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator GaussianMixture from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
wandb: Currently logged in as: xiaweijie1996 (weijie_xia) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /gpfs/home4/wxia/Prob-for-PPF/wandb/run-20250911_152705-g3ogzurj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-firefly-15
wandb: â­ï¸ View project at https://wandb.ai/weijie_xia/pinn-34
wandb: ðŸš€ View run at https://wandb.ai/weijie_xia/pinn-34/runs/g3ogzurj
Model Parameters: 2901686
Loaded scalers from: src/powersystems/psdistribution/34node/scalers.pkl
Sampled 100 data from GMM, mean: 41.9365732622234, std: 33.37408406324936, shape: (100, 66)
Loaded GMM from: src/powersystems/psdistribution/34node/gmm_power.pkl

Chunk:   0%|          | 0/1 [00:00<?, ?it/s]
Chunk: 1 of 1:   0%|          | 0/1 [00:00<?, ?it/s]
                                                    
Traceback (most recent call last):
  File "/gpfs/home4/wxia/Prob-for-PPF/src/training/pinn/main_34.py", line 186, in <module>
    main()
  File "/gpfs/home4/wxia/Prob-for-PPF/src/training/pinn/main_34.py", line 129, in main
    output_power_real, output_power_img = pinn_model(target_voltage[:,:,0], target_voltage[:,:,1]) # [B, N-1, 2]
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/src/models/pinn/pinn.py", line 120, in forward
    y_u, y_w = block(y_u, y_w)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/src/models/pinn/pinn.py", line 82, in forward
    s1 = self.convs1(s1.unsqueeze(1)).squeeze(1) # [B, N, N]
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 244, in forward
    input = module(input)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.67 GiB. GPU 0 has a total capacity of 39.49 GiB of which 2.09 GiB is free. Including non-PyTorch memory, this process has 37.39 GiB memory in use. Of the allocated memory 36.84 GiB is allocated by PyTorch, and 57.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mdulcet-firefly-15[0m at: [34mhttps://wandb.ai/weijie_xia/pinn-34/runs/g3ogzurj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250911_152705-g3ogzurj/logs[0m
srun: error: gcn67: task 0: Exited with exit code 1
srun: Terminating StepId=14615033.0

JOB STATISTICS
==============
Job ID: 14615033
Cluster: snellius
User/Group: wxia/wxia
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:10:48 core-walltime
Job Wall-clock time: 00:00:36
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 40.00 GB (40.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
