Host: gcn59.local.snellius.surf.nl
Thu Sep 11 16:00:47 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:CA:00.0 Off |                    0 |
| N/A   29C    P0             49W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
torch 2.8.0+cu128 cuda? True
/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/tensorpowerflow/utils.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/gpfs/home4/wxia/Prob-for-PPF
/gpfs/home4/wxia/Prob-for-PPF
Default case loaded.
Chunk:   0%|          | 0/1 [00:00<?, ?it/s]Chunk: 1 of 1:   0%|          | 0/1 [00:00<?, ?it/s]                                                    /gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator GaussianMixture from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(
wandb: Currently logged in as: xiaweijie1996 (weijie_xia) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /gpfs/home4/wxia/Prob-for-PPF/wandb/run-20250911_160129-j9xajbwh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-river-17
wandb: â­ï¸ View project at https://wandb.ai/weijie_xia/pinn-34
wandb: ðŸš€ View run at https://wandb.ai/weijie_xia/pinn-34/runs/j9xajbwh
Model Parameters: 2901686
Loaded scalers from: src/powersystems/psdistribution/34node/scalers.pkl
Sampled 100 data from GMM, mean: 40.162164887952066, std: 32.87412285190783, shape: (100, 66)
Loaded GMM from: src/powersystems/psdistribution/34node/gmm_power.pkl
Chunk:   0%|          | 0/1 [00:00<?, ?it/s]Chunk: 1 of 1:   0%|          | 0/1 [00:00<?, ?it/s]                                                    Traceback (most recent call last):
  File "/gpfs/home4/wxia/Prob-for-PPF/src/training/pinn/main_34.py", line 186, in <module>
    main()
  File "/gpfs/home4/wxia/Prob-for-PPF/src/training/pinn/main_34.py", line 129, in main
    output_power_real, output_power_img = pinn_model(target_voltage[:,:,0], target_voltage[:,:,1]) # [B, N-1, 2]
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/src/models/pinn/pinn.py", line 119, in forward
    y_u, y_w = block(y_u, y_w)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/src/models/pinn/pinn.py", line 81, in forward
    s1 = self.convs1(s1.unsqueeze(1)).squeeze(1) # [B, N, N]
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/container.py", line 244, in forward
    input = module(input)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/modules/activation.py", line 832, in forward
    return F.leaky_relu(input, self.negative_slope, self.inplace)
  File "/gpfs/home4/wxia/Prob-for-PPF/.venv/lib64/python3.9/site-packages/torch/nn/functional.py", line 1899, in leaky_relu
    result = torch._C._nn.leaky_relu(input, negative_slope)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacity of 39.49 GiB of which 663.25 MiB is free. Including non-PyTorch memory, this process has 38.84 GiB memory in use. Of the allocated memory 38.32 GiB is allocated by PyTorch, and 31.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mmorning-river-17[0m at: [34mhttps://wandb.ai/weijie_xia/pinn-34/runs/j9xajbwh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250911_160129-j9xajbwh/logs[0m
srun: error: gcn59: task 0: Exited with exit code 1
srun: Terminating StepId=14615716.0

JOB STATISTICS
==============
Job ID: 14615716
Cluster: snellius
User/Group: wxia/wxia
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:21:18 core-walltime
Job Wall-clock time: 00:01:11
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 40.00 GB (40.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
